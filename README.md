# Machine Learning

Fundamental of machine learning: Study cases and implementations.

![Roadmaps](MachineLearningAlgorithms.png)

## [Machine Learning by Andrew Ng at Coursera](https://www.coursera.org/learn/machine-learning)

If you getting started with Machine Learning, then this course may be perfect option as starting point. It lot of mathematical rigor, but you will found out that all of them are very fundametal. Honestly, if you successful at abstraction level using mathematic, then you can go ahead easily into practical solution using [Tensor Flow](https://www.tensorflow.org/) or [Scikit Learn](http://scikit-learn.org/). Good luck!

Here the tapology:

1. [Introduction](coursera/machine-learning-standford-univerity/Introduction)

    This section contains refreshness for Linear Algebra and introduce important concept for model evaluation.

    * [Introduction at The Nutshell](coursera/machine-learning-standford-univerity/Introduction/introduction.ipynb)
    * [Linear Algebra Review](coursera/machine-learning-standford-univerity/Introduction/Linear%20Algebra%20Review.ipynb)
    * [Model and Cost Function](coursera/machine-learning-standford-univerity/Introduction/Model%20and%20Cost%20Function.ipynb)
    * [Parameter Learning](coursera/machine-learning-standford-univerity/Introduction/Parameter%20Learning.ipynb)

2. [Linear Regression with Multiple Variables](coursera/machine-learning-standford-univerity/Linear%20Regression%20with%20Multiple%20Variables)

    This section will be most important topic in the course. Learning linear regression is the key to understand mathematical model used in statistical world. Linear regression is oldest mathematical model which is very matured and still used until today for social research and forecasting in economic.

    * [Multivariate Linear Regression](coursera/machine-learning-standford-univerity/Linear%20Regression%20with%20Multiple%20Variables/Multivariate%20Linear%20Regression.ipynb)
    * [Computing Parameters Analytically](coursera/machine-learning-standford-univerity/Linear%20Regression%20with%20Multiple%20Variables/Computing%20Parameters%20Analytically.ipynb)

3. [Logistic Regression](coursera/machine-learning-standford-univerity/Logistic%20Regression)

    Logistic regression is critical concept developed from the idea of linear Regression. It used in both social science, computer science and engineering. If you are interesting in computer field, than I am encourage you to working with [percoloation problem in algorithm course](https://www.coursera.org/learn/algorithms-part1/programming/Lhp5z/percolation) to get the bg picture.

    * [Classification and Representation](coursera/machine-learning-standford-univerity/Logistic%20Regression/Classification%20and%20Representations.ipynb)
    * [Logistic Regression Model](coursera/machine-learning-standford-univerity/Logistic%20Regression/Logistic%20Regression%20Model.ipynb)
    * [Multiclass Classification](coursera/machine-learning-standford-univerity/Logistic%20Regression/Multiclass%20Classification.ipynb)
    * [Solving the Problem of Overfitting](coursera/machine-learning-standford-univerity/Logistic%20Regression/Solving%20Problem%20of%20Overfitting.ipynb)

4. [Neural Network](coursera/machine-learning-standford-univerity/Neural%20Network)

    Neural network is most popular and widely used model to solve almost any problems. But, hold on, Neural Network itself tend to be independent field beyod machine learning since Neural Network can be mixed with broad concept in Artificial Intelligence, Neuro Science, and Deep Learning. But, it's worthy to learn it from the basic level.

    * [Neural Network in the Nutshell](coursera/machine-learning-standford-univerity/Neural%20Network/Neural%20Networks.ipynb)
    * [Backpropagation](coursera/machine-learning-standford-univerity/Neural%20Network/Backpropagation.ipynb)
    * [Backpropagation in Practice](coursera/machine-learning-standford-univerity/Neural%20Network/Backpropagation%20in%20Practice.ipynb)
    * [Applications](coursera/machine-learning-standford-univerity/Neural%20Network/Applications.ipynb)

5. [Support Vector Machine](coursera/machine-learning-standford-univerity/Support%20Vector%20Machine)

    Support vector machine is a model which is purely taken from linear algebra. The idea behind support vector machine is applying statictical concepts in linear algebra manner.

    * [Large Margin Classification](coursera/machine-learning-standford-univerity/Support%20Vector%20Machine/Large%20Margin%20Classification.ipynb)
    * [Kernels](coursera/machine-learning-standford-univerity/Support%20Vector%20Machine/Kernels.ipynb)

6. [Unsupervised Learning](coursera/machine-learning-standford-univerity/Unsupervised%20Learning)

    Unsupervised learning is hot topic in machine learning because the goal is to automate data labeling. Keep in mind that such automation is very hard to do, so you need some tricky techniques.

    * [Clustering](coursera/machine-learning-standford-univerity/Unsupervised%20Learning/Clustering.ipynb)
    * [Dimensionality Reduction](coursera/machine-learning-standford-univerity/Unsupervised%20Learning/Dimensionality%20Reduction.ipynb)
    * [Principal Component Analysis](coursera/machine-learning-standford-univerity/Unsupervised%20Learning/Principal%20Component%20Analysis.ipynb)

7. [Anomaly Detection](coursera/machine-learning-standford-univerity/Anomaly%20Detection)

    Anomaly detection is most practical implementation of support vector machine. It is widely used in industry and social science to detect fault and surely, anomalies.

    * [Density Estimation](coursera/machine-learning-standford-univerity/Anomaly%20Detection/Density%20Estimation.ipynb)
    * [Building an Anomaly Detection System](coursera/machine-learning-standford-univerity/Anomaly%20Detection/Building%20an%20Anomaly%20Detection%20System.ipynb)
    * [Low Rank Matrix Factorization](coursera/machine-learning-standford-univerity/Anomaly%20Detection/Low%20Rank%20Matrix%20Factorization.ipynb)
    * [Recommender System](coursera/machine-learning-standford-univerity/Anomaly%20Detection/Recommender%20Systems.ipynb)

8. [Large Scale Machine Learning](coursera/machine-learning-standford-univerity/Learning%20with%20Large%20Datasets)

    There are few people have capability to scale their machine leaning algorithm into large scale. Some who sucessful to that, such as Google, LinkedIn, Facebook, etc.

    * [Gradient Descent with Large Datasets](coursera/machine-learning-standford-univerity/Learning%20with%20Large%20Datasets/Gradient%20Descent%20with%20Large%20Datasets.ipynb)
    * [Advanced Topic](coursera/machine-learning-standford-univerity/Learning%20with%20Large%20Datasets/Advanced%20Topic.ipynb)

9. [Application Example: Photo OCR](coursera/machine-learning-standford-univerity/Application%20Example:%20Photo%20OCR)

    Just take a look and have fun.

    * [Photo OCR](coursera/machine-learning-standford-univerity/Application%20Example:%20Photo%20OCR/Photo%20OCR.ipynb)
    * [Artificial Data Syntesis](coursera/machine-learning-standford-univerity/Application%20Example:%20Photo%20OCR/Artificial%20Data%20Syntesis.ipynb)

## [Machine learning A-Z by Kirill Eremenko and Hadelin de Ponteves at Udemy](https://www.udemy.com/machinelearning/)

This is really really pratical machine learning course that everybody loved. This course offered flexibility in programming language, you can use either Python or R. Here the tapology:

1. [Data Preprocessing](udemy/machine%20learning%20A-Z/Part%201%20-%20Data%20Preprocessing)

    Covered very basic data processing techniques, such as:

    * Importing dataset.
    * Taking care of missing datas.
    * Encoding categorical data.
    * Splitting dataset into training set and test set.
    * Feature scaling.

2. [Regression](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression)

    Beware with decision tree and random forest, they are not exactly regression model, but tend to be classification model. Pay more attention on multivariate linear regression:

    * [Single variable linear regression](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%204%20-%20Simple%20Linear%20Regression)
    * [Multivariate linear regression](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%205%20-%20Multiple%20Linear%20Regression)
    * [Polynomial regression](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%206%20-%20Polynomial%20Regression)
    * [Support vector regression](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%207%20-%20Support%20Vector%20Regression%20%28SVR%29)
    * [Decision tree regression](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%208%20-%20Decision%20Tree%20Regression)
    * [Random forest regression](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%209%20-%20Random%20Forest%20Regression)
    * [Regularization methods](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%2011%20-%20Regularization%20Methods)
    * [Recap](udemy/machine%20learning%20A-Z/Part%202%20-%20Regression/Section%2012%20-%20Part%20Recap)

3. [Classification](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification)

    Beware with logistic regression, it is absolutely regression model, but its behave like classification method which map ordinal values into nominal values. Pay more attention on K-Nearest Neighbor (K-NN) and do not be confused with kernel SVM:

    * [Logistic regression](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2014%20-%20Logistic%20Regression)
    * [K-nearest neighbor](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2015%20-%20K-Nearest%20Neighbors%20%28K-NN%29)
    * [Support vector machine](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2016%20-%20Support%20Vector%20Machine%20%28SVM%29)
    * [Kernel SVM](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2017%20-%20Kernel%20SVM)
    * [Naive bayes](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2018%20-%20Naive%20Bayes)
    * [Decision tree](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2019%20-%20Decision%20Tree%20Classification)
    * [Random forest](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2020%20-%20Random%20Forest%20Classification)
    * [Evaluation](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2021%20-%20Evaluating%20Classification%20Models%20Performance)
    * [Recap](udemy/machine%20learning%20A-Z/Part%203%20-%20Classification/Section%2022%20-%20Part%20Recap)

4. [Clustering](udemy/machine%20learning%20A-Z/Part%204%20-%20Clustering)

    Pay more attention on k-means clustering. Fast on hierarchical clustering because in practice, it is highly customized. I recommend to go to part 7 after completing this Part:

    * [K-means clustering](udemy/machine%20learning%20A-Z/Part%204%20-%20Clustering/Section%2024%20-%20K-Means%20Clustering)
    * [Hierarchical clustering](udemy/machine%20learning%20A-Z/Part%204%20-%20Clustering/Section%2025%20-%20Hierarchical%20Clustering)
    * [Recap](udemy/machine%20learning%20A-Z/Part%204%20-%20Clustering/Section%2026%20-%20Part%20Recap)

5. [Association Rule Learning](udemy/machine%20learning%20A-Z/Part%205%20-%20Association%20Rule%20Learning)

    Basically, this methods laid on the concept of probability. Have fun:

    * [Apriori](udemy/machine%20learning%20A-Z/Part%205%20-%20Association%20Rule%20Learning/Section%2028%20-%20Apriori)
    * [Eclat](udemy/machine%20learning%20A-Z/Part%205%20-%20Association%20Rule%20Learning/Section%2029%20-%20Eclat)

6. [Reinforcement Learning](udemy/machine%20learning%20A-Z/Part%206%20-%20Reinforcement%20Learning)

    Introduce very basic concept of reinforcement learning. Have fun:

    * [Upper confidence bound](udemy/machine%20learning%20A-Z/Part%206%20-%20Reinforcement%20Learning/Section%2032%20-%20Upper%20Confidence%20Bound%20%28UCB%29)
    * [Thompson sampling](udemy/machine%20learning%20A-Z/Part%206%20-%20Reinforcement%20Learning/Section%2033%20-%20Thompson%20Sampling)

7. [Natural language processing](udemy/machine%20learning%20A-Z/Part%207%20-%20Natural%20Language%20Processing)

    Let's implements what we have learned from classification and clustering methods:

    * [Natural language processing](udemy/machine%20learning%20A-Z/Part%207%20-%20Natural%20Language%20Processing/Section%2036%20-%20Natural%20Language%20Processing)

8. [Deep learning](udemy/machine%20learning%20A-Z/Part%208%20-%20Deep%20Learning)

    Introduce very basic concept of deep learning. Have fun:

    * [Neural network](udemy/machine%20learning%20A-Z/Part%208%20-%20Deep%20Learning/Section%2039%20-%20Artificial%20Neural%20Networks%20%28ANN%29)
    * [Convolutional neural network](udemy/machine%20learning%20A-Z/Part%208%20-%20Deep%20Learning/Section%2040%20-%20Convolutional%20Neural%20Networks%20%28CNN%29)

9. [Dimensionality reduction](udemy/machine%20learning%20A-Z/Part%209%20-%20Dimensionality%20Reduction)

    Actually, this is kind of optimization method to gain better performance by sacrifying a little bit accuracy.

    * [Principal compenent analysis (PCA)](udemy/machine%20learning%20A-Z/Part%209%20-%20Dimensionality%20Reduction/Section%2043%20-%20Principal%20Component%20Analysis%20%28PCA%29)
    * [Linear descriminant analysis](udemy/machine%20learning%20A-Z/Part%209%20-%20Dimensionality%20Reduction/Section%2044%20-%20Linear%20Discriminant%20Analysis%20%28LDA%29)
    * [Kernel PCA](udemy/machine%20learning%20A-Z/Part%209%20-%20Dimensionality%20Reduction/Section%2045%20-%20Kernel%20PCA)

## Literatures

Here hand picked high quality papers and books to help you:

### Fundamental concepts

* [Calculus](literatures/calculus)
* [Linear algebra](literatures/linear%20algebra)
* [Probability](literatures/probability)

### Models

* [Association rule learning](literatures/association%20rule%20learning)
* [Classification](literatures/classification)
* [Clustering](literatures/clustering)
* [Convolutional neural network](literatures/convolution%20neural%20network)
* [Deep learning](literatures/deep%20learning)
* [Neural network](literatures/neural%20networks)
* [Regression](literatures/regression)
* [Reinforcement learning](literatures/reinforcement%20learning)

### Visualizations

* [Plotting](literatures/Plotting)

### Optimizations

* [Dimensionality Reduction](literatures/dimensional%20reduction)
* [LDA (Linear Descriminant Analysis)](literatures/lda)
* [Maximum entropy](literatures/maximum%20entropy)
* [Principal compenent analysis (PCA)](literatures/pca)

### Implementations

* [Natural language processing](literatures/NLP)

### Evaluations

* [Model selection](literatures/model%20selection)

### Software development

* [API](literatures/API)

### Advices from expert

* [Advices](literatures/advices)