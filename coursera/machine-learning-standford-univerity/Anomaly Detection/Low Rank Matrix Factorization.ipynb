{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization: Low Rank Matrix Factorization\n",
    "\n",
    "Given matrices X (each row containing features of a particular movie) and Θ (each row containing the weights for those features for a given user), then the full matrix Y of all predicted ratings of all movies by all users is given simply by: \\\\(Y = X\\Theta^T\\\\)\n",
    "\n",
    "Predicting how similar two movies i and j are can be done using the distance between their respective feature vectors x. Specifically, we are looking for a small value of \\\\(||x^{(i)} - x^{(j)}||\\\\).\n",
    "\n",
    "\n",
    "## Implementation Detail: Mean Normalization\n",
    "\n",
    "If the ranking system for movies is used from the previous lectures, then new users (who have watched no movies), will be assigned new movies incorrectly. Specifically, they will be assigned θ with all components equal to zero due to the minimization of the regularization term. That is, we assume that the new user will rank all movies 0, which does not seem intuitively correct.\n",
    "\n",
    "We rectify this problem by normalizing the data relative to the mean. First, we use a matrix Y to store the data from previous ratings, where the ith row of Y is the ratings for the ith movie and the jth column corresponds to the ratings for the jth user.\n",
    "\n",
    "We can now define a vector\n",
    "\n",
    "$$\\mu  = [\\mu_1, \\mu_2, \\dots , \\mu_{n_m}]$$\n",
    "\n",
    "such that\n",
    "\n",
    "$$\\mu_i = \\frac{\\sum_{j:r(i,j)=1}{Y_{i,j}}}{\\sum_{j}{r(i,j)}}$$\n",
    "\n",
    "Which is effectively the mean of the previous ratings for the ith movie (where only movies that have been watched by users are counted). We now can normalize the data by subtracting u, the mean rating, from the actual ratings for each user (column in matrix Y):\n",
    "\n",
    "As an example, consider the following matrix Y and mean ratings μ:\n",
    "\n",
    "$$Y = \n",
    "\\begin{bmatrix}\n",
    "    5 & 5 & 0 & 0  \\newline\n",
    "    4 & ? & ? & 0  \\newline\n",
    "    0 & 0 & 5 & 4 \\newline\n",
    "    0 & 0 & 5 & 0 \\newline\n",
    "\\end{bmatrix}, \\quad\n",
    " \\mu = \n",
    "\\begin{bmatrix}\n",
    "    2.5 \\newline\n",
    "    2  \\newline\n",
    "    2.25 \\newline\n",
    "    1.25 \\newline\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "The resulting Y′ vector is:\n",
    "\n",
    "$$Y' =\n",
    "\\begin{bmatrix}\n",
    "  2.5    & 2.5   & -2.5 & -2.5 \\newline\n",
    "  2      & ?     & ?    & -2 \\newline\n",
    "  -.2.25 & -2.25 & 3.75 & 1.25 \\newline\n",
    "  -1.25  & -1.25 & 3.75 & -1.25\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "Now we must slightly modify the linear regression prediction to include the mean normalization term:\n",
    "\n",
    "$$(\\theta^{(j)})^T x^{(i)} + \\mu_i$$\n",
    "\n",
    "Now, for a new user, the initial predicted values will be equal to the μ term instead of simply being initialized to zero, which is more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
